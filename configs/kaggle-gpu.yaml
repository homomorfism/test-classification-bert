model:
  lr: 1e-5
  num_epochs: 0
  model_type: 'bert-base-multilingual-uncased'


data:
  max_len: 256
  batch_size: 32
  num_workers: 2
  val_size: 0.05
  data_dir: '/kaggle/input/contradictory-my-dear-watson'
  current_dir: "/kaggle/working"

gpus: 1